import httpx, json, asyncio, uuid, os, aiofiles, websockets, mimetypes, re
from typing import Dict, Any, Optional, List, AsyncGenerator

from .config import (
    HTTP_TIMEOUT, WS_OPEN_TIMEOUT, WS_PING_INTERVAL,
    WS_PING_TIMEOUT, WORKFLOW_EXECUTION_TIMEOUT,
    DOWNLOAD_RETRY_ATTEMPTS, DOWNLOAD_RETRY_DELAY
)
from .workflow import ComfyWorkflow

_SENTINEL = object()

class ComfyUIClient:
    def __init__(self, base_url: str, proxy: Optional[str] = None):
        if "@" in base_url:
            token, real_base_url = base_url.split("@", 1)
            self.base_url = real_base_url.rstrip('/')
            self._headers = {"Authorization": f"Bearer {token}"}
        else:
            self.base_url = base_url.rstrip('/')
            self._headers = {}
        
        self.client_id = str(uuid.uuid4())
        ws_protocol = "ws" if self.base_url.startswith("http:") else "wss"
        host = self.base_url.split("://")[1]
        self.ws_address = f"{ws_protocol}://{host}/ws?clientId={self.client_id}"
        
        proxies = {"http://": proxy, "https://": proxy} if proxy else None
        
        self._client = httpx.AsyncClient(
            proxies=proxies,
            timeout=HTTP_TIMEOUT,
            follow_redirects=True,
            headers=self._headers
        )

    async def __aenter__(self): return self
    async def __aexit__(self, exc_type, exc_val, exc_tb): await self.close()
    async def close(self): await self._client.aclose()
    def _get_http_url(self, endpoint: str) -> str: return f"{self.base_url}{endpoint}"
    
    def _get_data_by_selector(self, data: Any, selector: str) -> Any:
        parts = re.split(r'\.|\[(\d+)\]', selector)
        parts = [p for p in parts if p]
        
        current_data = data
        for part in parts:
            if current_data is None: return _SENTINEL
            if isinstance(current_data, list) and part.isdigit():
                try:
                    current_data = current_data[int(part)]
                except IndexError:
                    return _SENTINEL
            elif isinstance(current_data, dict):
                current_data = current_data.get(part, _SENTINEL)
                if current_data is _SENTINEL:
                    return _SENTINEL
            else:
                return _SENTINEL
        return current_data

    async def execute_workflow(self, workflow: ComfyWorkflow, output_dir: str = "outputs") -> Dict[str, Any]:
        wf_to_run = await self.load_and_prepare_workflow(workflow.workflow_json_path, workflow._replacements)
        prompt_id = await self.queue_prompt(wf_to_run)
        if not prompt_id: return {"error": "æ— æ³•æäº¤å·¥ä½œæµåˆ°é˜Ÿåˆ—"}

        completed = await self.wait_for_prompt_completion(prompt_id)
        if not completed: return {"error": "å·¥ä½œæµæ‰§è¡Œå¤±è´¥æˆ–è¶…æ—¶"}

        history = await self.get_history(prompt_id)
        if not history: return {"error": "æ— æ³•è·å–æ‰§è¡Œå†å²è®°å½•"}

        print(f"\nâœ… ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„è¾“å‡º...")
        
        results = {}
        total_outputs_processed = 0

        for node_id, selectors in workflow._output_nodes.items():
            results[node_id] = {}
            async for item_result in self._get_outputs_for_node(history, node_id, selectors, output_dir):
                selector = item_result['selector']
                output = item_result['output']
                
                if selector in results[node_id]:
                    if not isinstance(results[node_id][selector], list):
                        results[node_id][selector] = [results[node_id][selector]]
                    results[node_id][selector].append(output)
                else:
                    results[node_id][selector] = output
                total_outputs_processed +=1

        if total_outputs_processed > 0:
            print(f"\nğŸ‰ğŸ‰ğŸ‰ å·¥ä½œæµæˆåŠŸå®Œæˆ! å…±å¤„ç† {total_outputs_processed} ä¸ªè¾“å‡ºé¡¹ã€‚")
        else:
            print("\nâš ï¸ å·¥ä½œæµå·²ç»“æŸï¼Œä½†æ²¡æœ‰å®šä¹‰æˆ–å¤„ç†ä»»ä½•è¾“å‡ºã€‚")
            
        return results

    async def _get_outputs_for_node(self, history: Dict[str, Any], target_node_id: str, selectors: List[str], output_dir: str) -> AsyncGenerator[Dict[str, Any], None]:
        node_outputs = history.get('outputs', {})
        
        print(f"æ­£åœ¨è·å–èŠ‚ç‚¹ '{target_node_id}' çš„è¾“å‡º...")

        if target_node_id not in node_outputs:
            for selector in selectors:
                yield {"selector": selector, "output": "éè¾“å‡ºèŠ‚ç‚¹"}
            return
        
        node_output_data = node_outputs[target_node_id]

        for selector in selectors:
            if selector == "DEFAULT_DOWNLOAD":
                found_files = False
                for key, value in node_output_data.items():
                    if isinstance(value, list) and value and isinstance(value[0], dict) and 'filename' in value[0]:
                        found_files = True
                        print(f"  - åœ¨èŠ‚ç‚¹ '{target_node_id}' çš„ '{key}' ä¸­æ‰¾åˆ°æ–‡ä»¶åˆ—è¡¨ï¼Œå‡†å¤‡ä¸‹è½½...")
                        for item in value:
                            file_path = await self._download_file(item, output_dir)
                            if file_path:
                                yield {"selector": selector, "output": file_path}
                            else:
                                yield {"selector": selector, "output": f"æ–‡ä»¶ '{item.get('filename')}' ä¸‹è½½å¤±è´¥"}
                if not found_files:
                    yield {"selector": selector, "output": "åœ¨èŠ‚ç‚¹ä¸­æœªæ‰¾åˆ°å¯ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨"}
                continue

            selected_data = self._get_data_by_selector(node_output_data, selector)
            
            if selected_data is _SENTINEL:
                yield {"selector": selector, "output": "æŒ‡å®šçš„JSONè·¯å¾„ä¸å­˜åœ¨"}
                continue

            data_to_process = selected_data if isinstance(selected_data, list) else [selected_data]

            for item in data_to_process:
                if isinstance(item, dict) and 'filename' in item:
                    file_path = await self._download_file(item, output_dir)
                    if file_path:
                        yield {"selector": selector, "output": file_path}
                    else:
                        yield {"selector": selector, "output": f"æ–‡ä»¶ '{item.get('filename')}' ä¸‹è½½å¤±è´¥"}
                else:
                    yield {"selector": selector, "output": str(item)}

    async def wait_for_prompt_completion(self, prompt_id: str, timeout: Optional[int] = None) -> bool:
        effective_timeout = timeout if timeout is not None else WORKFLOW_EXECUTION_TIMEOUT
        print(f"å¼€å§‹é€šè¿‡ WebSocket ç›‘å¬ä»»åŠ¡ {prompt_id} çš„æ‰§è¡ŒçŠ¶æ€ (æ€»è¶…æ—¶: {effective_timeout}s)...")

        attempts = 0
        while attempts < DOWNLOAD_RETRY_ATTEMPTS:
            try:
                async with websockets.connect(self.ws_address, ping_interval=WS_PING_INTERVAL, ping_timeout=WS_PING_TIMEOUT, open_timeout=WS_OPEN_TIMEOUT) as ws:
                    print("âœ… WebSocket è¿æ¥æˆåŠŸå»ºç«‹ã€‚")
                    attempts = 0

                    while True:
                        try:
                            message_data = await asyncio.wait_for(ws.recv(), timeout=effective_timeout)
                            if isinstance(message_data, str):
                                message = json.loads(message_data)
                                if message.get('type') == 'progress':
                                    data = message.get('data', {})
                                    print(f"  - è¿›åº¦æ›´æ–°: èŠ‚ç‚¹ {data.get('node', 'N/A')} - æ­¥æ•° {data.get('value', 0)}/{data.get('max', 1)}")
                                if message.get('type') == 'execution_success' and message.get('data', {}).get('prompt_id') == prompt_id:
                                    print("âœ… ä»»åŠ¡æ‰§è¡Œæµç¨‹ç»“æŸã€‚")
                                    return True
                        except asyncio.TimeoutError:
                            print(f"\nâŒ ç›‘å¬æ¶ˆæ¯è¶…æ—¶ ({effective_timeout}ç§’)ï¼Œæœªæ”¶åˆ°æ–°æ¶ˆæ¯ã€‚")
                            return False
            
            except Exception as e:
                attempts += 1
                print(f"âŒ ç›‘å¬ WebSocket æ—¶å‘ç”Ÿé”™è¯¯ (ç¬¬ {attempts}/{DOWNLOAD_RETRY_ATTEMPTS} æ¬¡å°è¯•): {e}")
                if attempts < DOWNLOAD_RETRY_ATTEMPTS:
                    print(f"   -> å°†åœ¨ {DOWNLOAD_RETRY_DELAY} ç§’åé‡è¿...")
                    await asyncio.sleep(DOWNLOAD_RETRY_DELAY)
                else:
                    print(f"   -> âŒ æ‰€æœ‰è¿ç»­çš„é‡è¿å°è¯•å‡å¤±è´¥ã€‚")
        
        return False
        
    async def _download_file(self, file_data: Dict[str, str], target_dir: str) -> Optional[str]:
        filename, subfolder, file_type = file_data.get('filename'), file_data.get('subfolder', ''), file_data.get('type')
        if not filename or not file_type: return None
        
        output_sub_dir = os.path.join(target_dir, file_type); os.makedirs(output_sub_dir, exist_ok=True)
        url = self._get_http_url("/view")
        params = {"filename": filename, "subfolder": subfolder, "type": file_type}
        
        for attempt in range(DOWNLOAD_RETRY_ATTEMPTS):
            try:
                async with self._client.stream("GET", url, params=params) as response:
                    response.raise_for_status()
                    output_path = os.path.join(output_sub_dir, filename)
                    async with aiofiles.open(output_path, 'wb') as f:
                        async for chunk in response.aiter_bytes():
                            await f.write(chunk)
                    
                    absolute_path = os.path.abspath(output_path)
                    return absolute_path.replace("\\", "/")

            except Exception as e:
                print(f"   -> âŒ ä¸‹è½½æˆ–ä¿å­˜ {filename} æ—¶å‘ç”Ÿé”™è¯¯ (ç¬¬ {attempt + 1}/{DOWNLOAD_RETRY_ATTEMPTS} æ¬¡å°è¯•): {e}")
                if attempt < DOWNLOAD_RETRY_ATTEMPTS - 1:
                    print(f"   -> å°†åœ¨ {DOWNLOAD_RETRY_DELAY} ç§’åé‡è¯•...")
                    await asyncio.sleep(DOWNLOAD_RETRY_DELAY)
                else:
                    print(f"   -> âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œæ”¾å¼ƒä¸‹è½½ {filename}ã€‚")

        return None

    async def upload_file(self, file_path: str, server_subfolder: str = "", overwrite: bool = True) -> Dict[str, Any]:
        if not os.path.exists(file_path): raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        print(f"å‡†å¤‡ä¸Šä¼ æ–‡ä»¶: {os.path.basename(file_path)}...")
        filename = os.path.basename(file_path)
        mime_type, _ = mimetypes.guess_type(filename)
        if mime_type is None: mime_type = 'application/octet-stream'
        payload = {'overwrite': str(overwrite).lower(), 'subfolder': server_subfolder}
        url = self._get_http_url("/upload/image")
        try:
            with open(file_path, 'rb') as f:
                files = {'image': (filename, f.read(), mime_type)}
                response = await self._client.post(url, files=files, data=payload)
                response.raise_for_status()
            result = response.json()
            print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ. æœåŠ¡å™¨æ–‡ä»¶å: {result['name']}")
            return result
        except (httpx.RequestError, httpx.HTTPStatusError) as e:
            print(f"âŒ ä¸Šä¼ æ–‡ä»¶æ—¶å‘ç”Ÿç½‘ç»œæˆ–HTTPé”™è¯¯: {e}")
            if isinstance(e, httpx.HTTPStatusError): print(f"   - æœåŠ¡å™¨å“åº”: {e.response.text}")
            raise
    
    @classmethod
    async def load_and_prepare_workflow(cls, workflow_path: str, replacements: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        print(f"æ­£åœ¨åŠ è½½å·¥ä½œæµ: {os.path.basename(workflow_path)}")
        if not os.path.exists(workflow_path): raise FileNotFoundError(f"å·¥ä½œæµæ–‡ä»¶æœªæ‰¾åˆ°: {workflow_path}")
        async with aiofiles.open(workflow_path, 'r', encoding='utf-8') as f: workflow = json.loads(await f.read())
        print("æ­£åœ¨åŠ¨æ€æ›¿æ¢èŠ‚ç‚¹å†…å®¹...")
        for node_id, inputs_to_replace in replacements.items():
            if node_id in workflow:
                for input_name, new_value in inputs_to_replace.items():
                    workflow[node_id]['inputs'][input_name] = new_value
                    print(f"   - èŠ‚ç‚¹ '{node_id}' çš„è¾“å…¥ '{input_name}' å·²æ›´æ–°ã€‚")
        return workflow

    async def queue_prompt(self, prepared_workflow: Dict[str, Any]) -> str:
        print("æ­£åœ¨å°†å·¥ä½œæµæäº¤åˆ°é˜Ÿåˆ—...")
        url = self._get_http_url("/prompt")
        payload = {"prompt": prepared_workflow, "client_id": self.client_id}
        try:
            response = await self._client.post(url, json=payload)
            response.raise_for_status()
            prompt_id = response.json().get("prompt_id")
            if prompt_id:
                print(f"âœ… å·¥ä½œæµæäº¤æˆåŠŸ. Prompt ID: {prompt_id}")
                return prompt_id
            else:
                print(f"âŒ æäº¤å·¥ä½œæµåæœªæ”¶åˆ° prompt_idã€‚æœåŠ¡å™¨å“åº”: {response.text}")
                return None
        except (httpx.RequestError, httpx.HTTPStatusError) as e:
            print(f"âŒ æäº¤å·¥ä½œæµæ—¶å‘ç”Ÿç½‘ç»œæˆ–HTTPé”™è¯¯: {e}")
            if hasattr(e, 'response') and e.response:
                print(f"   - æœåŠ¡å™¨å“åº”: {e.response.text}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ è§£ææœåŠ¡å™¨å“åº”æ—¶å‘ç”ŸJSONé”™è¯¯ã€‚è¿™é€šå¸¸æ„å‘³ç€æœåŠ¡å™¨è¿”å›äº†ä¸€ä¸ªé”™è¯¯é¡µé¢è€Œä¸æ˜¯æœ‰æ•ˆçš„JSONã€‚")
            print(f"   - åŸå§‹å“åº”å†…å®¹: {response.text}")
            return None


    async def get_history(self, prompt_id: str) -> Dict[str, Any]:
        url = self._get_http_url(f"/history/{prompt_id}")
        try:
            response = await self._client.get(url)
            response.raise_for_status()
            return response.json().get(prompt_id, {})
        except Exception as e:
            print(f"âŒ è·å–å†å²è®°å½•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {}
            
    async def view_tasks(self) -> Dict[str, List[Dict]]:
        try:
            queue_res = await self._client.get(self._get_http_url("/queue"))
            queue_res.raise_for_status()
            queue_data = queue_res.json()
            running_tasks = [{"prompt_id": item[1]} for item in queue_data.get('queue_running', []) if isinstance(item, list) and len(item) > 1]
            queued_tasks = [{"prompt_id": item[1]} for item in queue_data.get('queue_pending', []) if isinstance(item, list) and len(item) > 1]
            history_res = await self._client.get(self._get_http_url("/history"))
            history_res.raise_for_status()
            history_data = history_res.json()
            sortable_history = []
            for prompt_id, result in history_data.items():
                completion_timestamp = 0
                messages = result.get("status", {}).get("messages", [])
                for msg in messages:
                    if isinstance(msg, list) and len(msg) > 1 and msg[0] == 'execution_success':
                        if isinstance(msg[1], dict) and 'timestamp' in msg[1]:
                            completion_timestamp = msg[1]['timestamp']
                            break
                sortable_history.append({"prompt_id": prompt_id, "result": result, "timestamp": completion_timestamp})
            sortable_history.sort(key=lambda x: x.get('timestamp', 0), reverse=True)
            completed_tasks = []
            running_and_queued_ids = {t['prompt_id'] for t in running_tasks} | {t['prompt_id'] for t in queued_tasks}
            for item in sortable_history:
                prompt_id = item['prompt_id']
                if prompt_id in running_and_queued_ids: continue
                outputs_preview = "æ— è¾“å‡º"
                if 'outputs' in item['result']:
                    for node_output in item['result']['outputs'].values():
                        if 'images' in node_output and node_output['images']:
                           outputs_preview = node_output['images'][0]['filename']
                           break
                completed_tasks.append({"prompt_id": prompt_id, "outputs_preview": outputs_preview})
            return {"running": running_tasks, "queued": queued_tasks, "completed": completed_tasks}
        except Exception as e:
            print(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return {"running": [], "queued": [], "completed": []}

    async def interrupt_running_task(self) -> bool:
        print("æ­£å°è¯•ä¸­æ–­å½“å‰ä»»åŠ¡...")
        try:
            response = await self._client.post(self._get_http_url("/interrupt"))
            response.raise_for_status()
            return True
        except Exception as e:
            print(f"âŒ å‘é€ä¸­æ–­è¯·æ±‚å¤±è´¥: {e}")
            return False

    async def delete_queued_tasks(self, prompt_ids: List[str]) -> bool:
        print(f"æ­£å°è¯•ä»é˜Ÿåˆ—ä¸­åˆ é™¤ä»»åŠ¡: {prompt_ids}...")
        try:
            response = await self._client.post(self._get_http_url("/queue"), json={"delete": prompt_ids})
            response.raise_for_status()
            return True
        except Exception as e:
            print(f"âŒ å‘é€åˆ é™¤è¯·æ±‚å¤±è´¥: {e}")
            return False
